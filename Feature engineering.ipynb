{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techniques of Feature Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first question to ask is what is feature engineering and why it is needed for a Data Scientiest? It is hard to imagine a machine learning algorithm without data. Actually all machine learning algorithms use input data to create some output of it. Data usually in a form of stractured columns in excell/csv files, and thouse columns values are treated as features. Algorithms need this features to work properly. Lets say you have data of travelers and you want to predict if they will come back to that airport. \n",
    " <img src=\"trav.png\" />\n",
    "There are 2 given features in this data set, \"date arrival\" and \"date departure\", this dates a lon my not be to much handly for an algorithms them self, but if we calculated amount of time a traveler spent in a city and days of departure we may have more meaningfull information about that traveler for an algorithm or we call it a model. Maybe users that did not spend much time would come back to see more seight seeing or the opposite they may not like the stay and rerutned before they planned. That is why it is important to select/create features out of the data for your model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"The features you use influence more than everything else the result. No algorithm alone, to my knowledge, can supplement the information gain given by correct feature engineering.\"\n",
    "â€” Luca Massaron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A difinition from wiki::\n",
    "\"Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work. Feature engineering is fundamental to the application of machine learning, and is both difficult and expensive. The need for manual feature engineering can be obviated by automated feature learning.\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how important feature engineering is we can take a look at <a href=\"https://www.forbes.com/sites/gilpress/2016/03/23/data-preparation-most-time-consuming-least-enjoyable-data-science-task-survey-says/#70a816a06f63\">Forbes</a> surve based on it 80% of time is spent on data massaging\n",
    "\n",
    "<img src=\"survey.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also called data \"data munging\" or preparations that may take up to 95% of your time being a Data Scientiest, which may be very boaring, that is why we will take a look at some automation technics of it, but first lets understand the basics and the main technics of feature engineering.\n",
    "we wil be using some python libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets get some basic hands on feeling with manual feature engineering. We will use Home Credit Default Risk data\n",
    "* bureau: information about client's previous loans with other financial institutions reported to Home Credit. Each previous loan has its own row.\n",
    "* bureau_balance: monthly information about the previous loans. Each month has its own row.\n",
    "Manual feature engineering can be a tedious process and often relies on domain expertise. As I am not a domain expert in loands and what cause to a default i will try to generate good amount of features and let model decide. Later we can use PCA or feature reduction using the feature importance from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in bureau\n",
    "bureau = pd.read_csv('input/bureau.csv')\n",
    "bureau.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby the client id (SK_ID_CURR), count the number of previous loans, and rename the column\n",
    "previous_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(columns = {'SK_ID_BUREAU': 'previous_loan_counts'})\n",
    "previous_loan_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to the training dataframe\n",
    "train = pd.read_csv('input/application_train.csv')\n",
    "train = train.merge(previous_loan_counts, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# Fill the missing values with 0 \n",
    "train['previous_loan_counts'] = train['previous_loan_counts'].fillna(0)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Feature engineering technics\n",
    "## Think of feature engineering methods, we can list some of the most common practices:\n",
    "\n",
    "1. Dealing with categorical features\n",
    " 1.1. Bucketing bins and One-Hot encoding\n",
    " 1.2\n",
    "3. Feature transformation\n",
    "3.1 log\n",
    "3.2 feature expentions, PolynomialFeatures, extraction\n",
    "3.3 Scaling or normalizing features within a range \n",
    "4. Feature crossing - (long, lat) date,2-May-2019\n",
    "5. Row aggregation, group by, \n",
    "5.1 Moving averages with panda df\n",
    "6. Embedding - transformation, part of training. trainable/ non trainable, word2vec pre training. retrieve, train, seize, bottle neck tensor, calculate till you reach some training threshold, look up,\n",
    " feature columns.\n",
    "integers categorical\n",
    "7. simple model improved after feature engineering.\n",
    "column name as variable,\n",
    "implement in TF, feature column, \n",
    "notebook out estimator \n",
    "models in tf\n",
    "panda -> convert to tf tf.dataset api\n",
    "use tf as possible for education\n",
    "put transformation in a map\n",
    "moving average in pandas\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.75\n",
    "#Dropping columns with missing value rate higher than threshold\n",
    "data = data[data.columns[data.isnull().mean() < threshold]]\n",
    "\n",
    "#Dropping rows with missing value rate higher than threshold\n",
    "data = data.loc[data.isnull().mean(axis=1) < threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas and numpy for data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Suppress warnings from pandas\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install featuretools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import featuretools as ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
